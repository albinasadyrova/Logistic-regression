# Классификация рукописных цифр с использованием KNN и логистической регрессии

Этот проект реализует алгоритмы классификации для определения рукописных цифр с использованием метода k ближайших соседей (KNN) и логистической регрессии.

## Описание

### KNN (метод k ближайших соседей)

Метод k ближайших соседей (KNN) используется для классификации изображений рукописных цифр. Мы реализуем KNN без использования сторонних библиотек, вычисляя расстояния между объектами и выбирая наиболее часто встречающиеся классы среди k ближайших соседей.

### Логистическая регрессия

Логистическая регрессия также применяется для бинарной классификации (цифра '5' против всех остальных). Мы реализуем логистическую регрессию для оценки вероятности принадлежности к классу '5' с использованием сигмоидной функции.

## Результаты

Мы обучаем обе модели на наборе данных рукописных цифр, разделяя данные на обучающий и тестовый наборы. Затем оцениваем качество каждой модели на тестовом наборе данных с помощью метрики accuracy (точность).

### Примеры результатов

- **Метод k ближайших соседей (KNN)**:
  - K=3: Точность на тестовом наборе данных: 0.98
  - K=5: Точность на тестовом наборе данных: 0.97
  - K=7: Точность на тестовом наборе данных: 0.97
  - K=9: Точность на тестовом наборе данных: 0.97

### Логистическая регрессия (с разными скоростями обучения)

Для различных значений скорости обучения (`learning_rate`):

- Логистическая регрессия (learning_rate=0.001): Точность на тестовом наборе данных: 0.95
- Логистическая регрессия (learning_rate=0.01): Точность на тестовом наборе данных: 0.96
- Логистическая регрессия (learning_rate=0.1): Точность на тестовом наборе данных: 0.97

## Запуск

Чтобы запустить проект, убедитесь, что у вас установлены библиотеки `numpy` и `scikit-learn`. Запустите файл `main.py` для обучения моделей и оценки их качества на тестовом наборе данных.


